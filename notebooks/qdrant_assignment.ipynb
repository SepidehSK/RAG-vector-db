{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semestral Home Assignment \n",
    "In the semestral home assignment you are tasked with designing and implementing a production ready information retrieval (IR) system with the use of Qdrant. <br>\n",
    "First will need to implement scalable Qdrant cluster with the principles of NoSQL (sharding, replication quorum). <br>\n",
    "Then, you will implement the vector search with Qdrant using all the advanced features of the vector database. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Sepideh Sanedoust Karseidani, učo 554733      \n",
    "Year: 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\MUNI\\4-Semester\\PA195 NoSQL Databases\\VectorDB\\pa195_semestral_assignment_2025\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any, cast, Callable\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets.dataset_dict import Dataset\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import models\n",
    "from qdrant_client.http.models.models import QueryResponse\n",
    "from fastembed import TextEmbedding, SparseTextEmbedding, LateInteractionTextEmbedding\n",
    "from fastembed.sparse.sparse_embedding_base import SparseEmbedding\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from notebooks.utils import evaluate_retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load environment variables. **Do not forget to create a .env file in the root directory based on the .env.example file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up local instance of Qdrant through docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Network pa195_semestral_assignment_2025_qdrant-cluster  Creating\n",
      " Network pa195_semestral_assignment_2025_qdrant-cluster  Created\n",
      "time=\"2026-01-14T23:19:50+01:00\" level=warning msg=\"Found orphan containers ([pa195_semestral_assignment_2025-qdrant-node1-1 pa195_semestral_assignment_2025-qdrant-node2-1 pa195_semestral_assignment_2025-qdrant-node3-1]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.\"\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_3-1  Creating\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_1-1  Creating\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_2-1  Creating\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_3-1  Created\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_2-1  Created\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_1-1  Created\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_1-1  Starting\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_3-1  Starting\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_2-1  Starting\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_2-1  Started\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_3-1  Started\n",
      " Container pa195_semestral_assignment_2025-qdrant_node_1-1  Started\n"
     ]
    }
   ],
   "source": [
    "#!docker run -p 6333:6333 -p 6334:6334 -d --name qdrant-server qdrant/qdrant:v1.16\n",
    "\n",
    "!docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the Qdrant client by connecting to the server running as a docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(host=os.environ[\"QDRANT_HOST\"], port=int(os.environ[\"QDRANT_PORT\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Data Loading\n",
    "Load the data from the Hugging Face dataset [Zovi3/pa195_semestral_assignment](https://huggingface.co/datasets/Zovi3/pa195_semestral_assignment/upload/main), explore it and extract/preprocess it if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import query dataset from https://huggingface.co/datasets/Zovi3/pa195_semestral_assignment/tree/main\n",
    "query_dataset: Dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"hf://datasets/Zovi3/pa195_semestral_assignment/query-all-MiniLM-L6-v2-100-filters-embedded-results/train.jsonl\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import documents dataset from https://huggingface.co/datasets/Zovi3/pa195_semestral_assignment/tree/main\n",
    "documents: Dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"hf://datasets/Zovi3/pa195_semestral_assignment/corpus-all-MiniLM-L6-v2-50K-groups-multi-vector/train.jsonl\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the homework you will work with `sentence-transformers/all-MiniLM-L6-v` from fastembed library. <br>\n",
    "These embedding are precomputed for you in the assignment dataset, but you will need to used model when running the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings are precomputed so you can save some memory by not loading the model\n",
    "embedding_model = TextEmbedding('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embedding_model_size = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Retrieval Model\n",
    "Some queries require the prioritization of the certain keywords. <br>\n",
    "Therefor, you will need to use BM25 algorithm to boost the documents with these keywords during retrieval. <br>\n",
    "Note that BM25 is not taken into account in the dataset, so you will need to apply when uploading and indexing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_model = SparseTextEmbedding(\"Qdrant/bm25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Vector Model\n",
    "It is general good practice to include reranking model in the IR system. <br>\n",
    "Reranking uses stronger model to select the most relevant documents from the initial retrieval. <br>\n",
    "You will implement reranking with multi-vector late interaction embedding ColBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings are precomputed so you can save some memory by not loading the model\n",
    "multi_vector_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")\n",
    "multi_vector_model_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Data Modelling\n",
    "In this task you will create proper data model for your data including vector representations, index configuration, distance functions and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.1 - HNSW Index Configuration\n",
    "Configure the HNSW index for the retrieval. <br>\n",
    "**Change the ef_construct parameter to 64 to speed the build time at the cost of the recall.** <br>\n",
    "We do this for practical reasons, to enable you iterate over the notebook faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change ef_construct parameter to 64 to speed the build time at the cost of the recall\n",
    "ef_construct = 64\n",
    "# TODO Configure HNSW index\n",
    "hnsw_config = models.HnswConfigDiff(ef_construct=ef_construct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2 - Collection Creation\n",
    "Create model for your data. You should create three vector representations for your data. <br>\n",
    "There should be one representation for each model defined above. <br>\n",
    "For multi-vector model make sure to disable the vector index since it will be used only for reranking. <br>\n",
    "Also, do not forget that multi-vector computation of similarity is not done only through the cosine similarity (check the lecture for more info). <br>\n",
    "Configure proper modifier for the sparse vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"ms_macro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing collection: ms_macro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sepideh\\AppData\\Local\\Temp\\ipykernel_3624\\1887498216.py:10: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  collection_created = client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection 'ms_macro'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client.delete_collection(COLLECTION_NAME)\n",
    "    print(f\"Deleted existing collection: {COLLECTION_NAME}\")\n",
    "except: \n",
    "    print(f\"Collection {COLLECTION_NAME} does not exist\")\n",
    "\n",
    "\n",
    "# TODO: Configure collection creation\n",
    "# Dense and sparse enable hybrid search; multi-vector is for reranking to improve precision.  \n",
    "collection_created = client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\n",
    "        \"dense\": models.VectorParams(\n",
    "            size=embedding_model_size,  # 384-dim\n",
    "            distance=models.Distance.COSINE,\n",
    "            hnsw_config=hnsw_config,\n",
    "        ),\n",
    "        \"multi_vector\": models.VectorParams(\n",
    "            size=multi_vector_model_size,   # 128-dim\n",
    "            distance=models.Distance.DOT,  # Placeholder; ColBERT reranking uses MaxSim (max dot-product)\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM # MaxSim (Much better semantics)\n",
    "            ),\n",
    "            hnsw_config=None,  # Disable indexing for reranking only\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"sparse\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,  # Applying inverse document frequency weighting for better BM25 scoring\n",
    "        ),\n",
    "    },\n",
    "    on_disk_payload=True,\n",
    ")\n",
    "\n",
    "if collection_created:\n",
    "    print(f\"Created collection '{COLLECTION_NAME}'.\")\n",
    "else:\n",
    "    print(\"Collection creation failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.3 - Create Payload Index & Disable Quantization\n",
    "Configure keyword payload index for the `groups` field. Make sure that payload index is on-disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload index created for field 'groups'\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create payload index\n",
    "payload_index_created = client.create_payload_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    field_name=\"groups\",\n",
    "    field_schema=models.KeywordIndexParams(\n",
    "        type=\"keyword\",\n",
    "        on_disk=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Disable quantization\n",
    "client.update_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    quantization_config=models.Disabled.DISABLED,\n",
    ")\n",
    "\n",
    "if payload_index_created:\n",
    "    print(f\"Payload index created for field 'groups'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Data Upload\n",
    "Upload vector embeddings and metadata to the created collection, make sure to upload the vectors metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sparse embeddings...\n",
      "Processing document 0/50000\n",
      "Processing document 10000/50000\n",
      "Processing document 20000/50000\n",
      "Processing document 30000/50000\n",
      "Processing document 40000/50000\n",
      "Upserting documents...\n",
      "Collection info: 50000 points in collection\n"
     ]
    }
   ],
   "source": [
    "points: list[models.PointStruct] = []\n",
    "\n",
    "bm25_iter = bm25_model.embed(documents[\"text\"])\n",
    "\n",
    "print(\"Generating sparse embeddings...\")\n",
    "doc: dict[str, Any]\n",
    "for i, doc in enumerate(documents):  # type: ignore\n",
    "    if i % 10000 == 0:  # Print every 10000 documents\n",
    "        print(f\"Processing document {i}/{len(documents)}\")\n",
    "\n",
    "    # TODO: Implement data upload\n",
    "    # Generate Sparse Vector (BM25) on the fly\n",
    "    sparse_result = next(bm25_iter)\n",
    "    \n",
    "    # Convert to Qdrant SparseVector\n",
    "    sparse_vector = models.SparseVector(\n",
    "        indices=sparse_result.indices.tolist(),\n",
    "        values=sparse_result.values.tolist()\n",
    "    )\n",
    "\n",
    "    point = models.PointStruct(\n",
    "        id=doc[\"id\"],\n",
    "        vector={\n",
    "            \"dense\": doc[\"embedding\"],  # Precomputed dense embedding\n",
    "            \"sparse\": sparse_vector,    # BM25 sparse embedding\n",
    "            \"multi_vector\": doc[\"multi_vector_embedding\"],  # Precomputed ColBERT multi-vector\n",
    "        },\n",
    "        payload={\n",
    "            \"text\": doc[\"text\"],\n",
    "            \"groups\": doc[\"groups\"],\n",
    "        },\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "print(\"Upserting documents...\")\n",
    "client.upload_points(collection_name=COLLECTION_NAME, points=points, batch_size=128)\n",
    "\n",
    "print(f\"Collection info: {client.get_collection(COLLECTION_NAME).points_count} points in collection\")\n",
    "assert client.get_collection(COLLECTION_NAME).points_count == len(documents), f\"Expected {len(documents)} points in collection, got {client.get_collection(COLLECTION_NAME).points_count}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Design Complex Query\n",
    "Your task is to design a complex query that will include hybrid search, filtering, reranking and metadata boosting. <br>\n",
    "**The result of this task should be one Qdrant query (do not add any postprocessing logic outside of the Qdrant query)!**\n",
    " \n",
    "**Subtasks:**\n",
    "1. Define query filter with relation to the `groups` field, do not forget there can be filter values in the query.\n",
    "    - Think about in which prefetch you should apply the filter.\n",
    "2. Define sparse and dense search prefetche, the limit for the retrieval should be 100 objects.\n",
    "3. Define fusion of the two rankings with Reciprocal Rank Fusion (RRF).\n",
    "4. Rerank the results with ColBERT multi-vector model, use 50 documents for reranking.\n",
    "5. Boost the results with metadata weighting, use `group_1` with weight 0.05 and `group_2` with weight 0.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_query_text(query_text: str, filter_values: list[str]) -> str:\n",
    "    if filter_values:\n",
    "        return f\"{query_text} {' '.join(filter_values)}\"\n",
    "    return query_text\n",
    "\n",
    "def rag_context_retrieval(query: dict[str, Any]) -> QueryResponse:\n",
    "    # TODO: Implement correct embeddings usage\n",
    "    # Generate query embeddings using pre-trained models\n",
    "    query_dense_embedding = list(embedding_model.embed([query['text']]))[0]\n",
    "    \n",
    "    sparse_input_text = build_sparse_query_text(query['text'], query.get('filters', []))\n",
    "    query_sparse_result = list(bm25_model.embed([sparse_input_text]))[0]\n",
    "    query_sparse_embedding = models.SparseVector(\n",
    "        indices=query_sparse_result.indices.tolist(),\n",
    "        values=query_sparse_result.values.tolist()\n",
    "    )\n",
    "    \n",
    "    query_multi_vector_embedding = list(multi_vector_model.embed([query['text']]))[0]\n",
    "\n",
    "    # Task 4.1 - Define query filter\n",
    "    filter_condition = None  # TODO: Implement filters\n",
    "    if query.get('filters'):\n",
    "        filter_condition = models.Filter(\n",
    "            must=[models.FieldCondition(key=\"groups\", match=models.MatchAny(any=query['filters']))]\n",
    "        )\n",
    "\n",
    "    # Candidates for fusion/reranking\n",
    "    sparse_limit = 100\n",
    "    dense_limit = 100\n",
    "    # Task 4.2 - Define sparse and dense search. Set their limit to 100.\n",
    "    prefetch_sparse_and_dense_search: list[models.Prefetch] = [\n",
    "        # TODO: Implement sparse and dense prefetches\n",
    "        models.Prefetch(\n",
    "            query=query_dense_embedding,\n",
    "            using=\"dense\",\n",
    "            filter=filter_condition,\n",
    "            limit=dense_limit\n",
    "        ),\n",
    "        models.Prefetch(\n",
    "            query=query_sparse_embedding,\n",
    "            using=\"sparse\",\n",
    "            filter=filter_condition,\n",
    "            limit=sparse_limit\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Task 4.3 - Define fusion of the two rankings (set the k parameter of the query to 60 to mitigate effect of high rankings)\n",
    "    rff_k = 60\n",
    "\n",
    "    prefetch_fused_rankings: list[models.Prefetch] = [\n",
    "        # TODO: Implement rank fusion\n",
    "        models.Prefetch(\n",
    "            query=models.RrfQuery(rrf=models.Rrf(k=rff_k)),  # Tune RRF k for Fusion, k=60 is a good default\n",
    "            prefetch=prefetch_sparse_and_dense_search,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Task 4.4 - Rerank the results with ColBERT multi-vector model taking 50 documents.\n",
    "    reranking_limit = 50  # Tunnable for better precision (more documents, improving selection)\n",
    "    prefetch_multi_vector_reranking: list[models.Prefetch] = [\n",
    "        # TODO: Implement multi-vector reranking\n",
    "        models.Prefetch(\n",
    "            query=query_multi_vector_embedding,\n",
    "            using=\"multi_vector\",\n",
    "            prefetch=prefetch_fused_rankings,\n",
    "            limit=reranking_limit\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    group_1_boost_weight = 0.05  # Tunnable for better precision\n",
    "    group_2_boost_weight = 0.1  # Tunnable for better precision\n",
    "    final_query_limit = 10\n",
    "    # Task 4.5 - Boost following \"groups\" in the search: \"group_1\" with weight 0.05 and \"group_2\" with weight 0.1\n",
    "    final_result: QueryResponse = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        # TODO: Implement final query with metadata boosting\n",
    "        # TODO: This query should be built from all the prefetches\n",
    "        prefetch=prefetch_multi_vector_reranking,\n",
    "        query=models.FormulaQuery(\n",
    "            formula=models.SumExpression(sum=[\n",
    "                \"$score\",\n",
    "                models.MultExpression(mult=[group_1_boost_weight, models.FieldCondition(key=\"groups\", match=models.MatchAny(any=[\"group_1\"]))]),\n",
    "                models.MultExpression(mult=[group_2_boost_weight, models.FieldCondition(key=\"groups\", match=models.MatchAny(any=[\"group_2\"]))])\n",
    "            ]\n",
    "        )),\n",
    "        using=\"multi_vector\",\n",
    "        limit=final_query_limit\n",
    "    )\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You achieved 0.879 enough to pass ✅!\n"
     ]
    }
   ],
   "source": [
    "avg_retrieval_precision = evaluate_retrieval(rag_context_retrieval, query_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average recall: 0.877\n",
      "Recall requirement met ✅!\n"
     ]
    }
   ],
   "source": [
    "# from typing import Any, Callable\n",
    "# from qdrant_client.http.models.models import QueryResponse\n",
    "# from datasets import Dataset\n",
    "# from typing import cast\n",
    "\n",
    "# def calculate_recall(retrieved_docs: list[int], relevant_docs: list[int]) -> float:\n",
    "#     if not relevant_docs:\n",
    "#         return 1.0 if not retrieved_docs else 0.0  # Edge case: no relevant docs\n",
    "    \n",
    "#     relevant_retrieved = len(set(retrieved_docs) & set(relevant_docs))\n",
    "#     return relevant_retrieved / len(relevant_docs)\n",
    "\n",
    "# def evaluate_recall(rag_context_retrieval: Callable[[dict[str, Any]], QueryResponse], query_dataset: Dataset) -> float:\n",
    "#     total_recall: float = 0.0\n",
    "    \n",
    "#     for i in range(len(query_dataset)):\n",
    "#         query: dict[str, Any] = cast(dict[str, Any], query_dataset[i])\n",
    "        \n",
    "#         query_response: QueryResponse = rag_context_retrieval(query)\n",
    "#         retrieved_docs: list[int] = [cast(int, point.id) for point in query_response.points]\n",
    "        \n",
    "#         relevant_docs: list[int] = query[\"result\"][\"point_ids\"]\n",
    "        \n",
    "#         recall: float = calculate_recall(retrieved_docs, relevant_docs)\n",
    "#         total_recall += recall\n",
    "    \n",
    "#     avg_recall = total_recall / len(query_dataset) if len(query_dataset) > 0 else 0.0\n",
    "#     print(f\"Average recall: {avg_recall}\")\n",
    "#     return avg_recall\n",
    "\n",
    "# # Usage: Replace 'rag_context_retrieval' and 'query_dataset' with your variables\n",
    "# avg_recall = evaluate_recall(rag_context_retrieval, query_dataset)\n",
    "# if avg_recall >= 0.8:\n",
    "#     print(\"Recall requirement met ✅!\")\n",
    "# else:\n",
    "#     print(\"Recall below 80% ❌\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-template",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
